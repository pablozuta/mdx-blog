---
title: Python Libraries for Data Science 
tags:
  - python
  - numpy
  - matplotlib
  - data science
date: 12-01-2023
---

## NumPy
Why is it a good idea to use NumPy rather than basic Python data structures and functions?
Data can come from many different sources, but often we can consider them as _arrays_ (or grids) of numbers. For instance, an image can be seen as a two dimensional array (or matrix) where each cell represents the intensity of a pixel. Being able to efficiently handle these arrays is really important, and NumPy is what allows us to do so.
NumPy stands for **Numerical Python** and provides us with an interface for operating on numbers. From a user point of view, NumPy arrays behave similarly to Python lists. However, it is much _faster_ to operate on NumPy arrays, especially when they are large. NumPy arrays are at the foundation of the whole Python data science ecosystem.
Let's start by importing NumPy:

```python
import numpy as np
```
### Create a Numpy Array
Unlike Python lists, NumPy arrays can only hold _one specific_ type of data. The exact type of array is automatically worked out at its creation, and has an impact on the operations that can be performed on it. You can also specify the type manually. We'll see examples of each shortly.

```python
# Array of integers
np.array([1, 3, 4, 5, 8])
```
And if you want to manually set the data type:

```python
np.array([2, 5, 7, 43], dtype='float32')
```
Unlike Python lists, NumPy arrays can be explicitly multidimensional. This means that NumPy recognizes multidimensional tables (for example, a table of numbers with rows and columns).
It's often more efficient, especially for large arrays, to create them yourself. NumPy provides us with quite a few ways to do this:

```python
# An array of length 10, filled with 0:
np.zeros(10, dtype=int)
# An array of size 3x5 filled with 1.0 (float)
np.ones((3, 5), dtype=float)
# An array of size 3x5 filled with 3.14
np.full((3, 5), 3.14)
# An array containing a linear sequence starting at 0 and 
# going up to 20, with steps of 2
np.arange(0, 20, 2)
# An array of 5 numbers, linearly spaced between 0 and 1
np.linspace(0, 1, 5)
# An array of the given shape and populate it with random
# samples. You can also try using "randint" and "normal"
np.random.random((3, 3))
# The identity matrix of size 3
np.eye(3)
```
NumPy arrays have some very useful properties! For example, if you want to know how many dimensions an array has, you can use  .ndim . To confirm the dimension of a shape, you can also look at its shape, using  .shape . To look at the size of the array, or in other words, to see how many elements it has, we can use  .size. Finally, if we want to see the data type of the elements, we can look at that using  .dtype.

```python
np.random.seed(0)
x1 = np.random.randint(10, size=6)  
# 1-dimensional array
print("Number of dimensions: ", x1.ndim)
print("Shape: ", x1.shape)
print("Size: ", x1.size)
print("Type: ", x1.dtype)
```
#### Accessing a single element

You'll often need to access specific elements of an array. This is called **indexing**. Fortunately, this is really easy with NumPy!

```python
print(x1)
# The first element
print(x1[0])
# The last element
print(x1[-1])

x2 = np.random.randint(10, size=(3, 4))  
# 2-dimensional array
print(x2[0,1])

# You can also modify values:
x1[1] = "1000"
print(x1)

# Mind the type 
x1[1] = 3.14
print(x1)
```

## Matplotlib

#### Visualize Uncertainty
Another aspect of plotting is the **_degree of uncertainty associated with estimates_.**
To visualize uncertainty we are going to use what we call **error bars**.

##### Discrete Data
In the case of discrete data, we often use error bars to represent the uncertainty inherent to each point's value. Often, the length of the bars matches the _standard deviation_ of the _empirical observations_.

```python
x = np.linspace(0, 10, 50)
dy = 0.8
y = np.sin(x) + dy * np.random.randn(50)
plt.errorbar(x, y, yerr=dy, fmt='.k');
plt.show()
```

Errorbar takes as argument the x-coordinates, y-coordinates and lengths of each bar (one bar per point)  yerr . Note the  fmt  argument. It allows you to choose the color (here black) and the shape of the markers on the graph in a really concise way. Errorbar  also allows you to further customize the appearance of the graph.

```python
x = np.linspace(0, 10, 50)
dy = 0.8
y = np.sin(x) + dy * np.random.randn(50)
plt.errorbar(x, y, yerr=dy, fmt='o', color="black",
			ecolor='lightgray', elinewidth=3, capsize=0);
```

### Customize your plots
Up to this point, we have been constructing plots from the ground up, but you can actually use a set of _preconfigured_ properties called **styles**.
let's print the first six styles that we have.

```python
print(plt.style.available[:6])
fig = plt.figure(figsize=(12, 8))
for i in range(6):
    fig.add_subplot(3, 2, i + 1)
    plt.style.use(plt.style.available[i])
    plt.plot(x, y)
    plt.text(s=plt.style.available[i], x=5, y=2, color='red')
```

## Explore your data visually with Seaborn
Seaborn  is a library that improves Matplotlib's functionality, replaces some default settings and functions, and adds new features.

Seaborn was created to correct three **defects of Matplotlib.** As a standalone, Matplotlib:

-   Can't generate graphics of high aesthetic quality (especially in pre 2.0 versions).
    
-   Lacks the functionality to easily create sophisticated statistical analyses.
    
-   Features functions that aren't designed to interact with Panda Dataframes (which we will see in the next chapter).
    

Luckily, Seaborn addresses these problems! It still uses Matplotlib "under the hood", but does so by exposing more intuitive functions.

```python
import seaborn as sns
sns.set()
x = np.linspace(0, 10, 500)
y = np.random.randn(500)
plt.plot(x,y)
plt.show()
```
Seaborn also provides us with functions to generate useful plots for statistical analysis. For example,`distplot` lets you not only view the histogram of a sample, but also estimate the distribution from which the sample is derived.

```python
sns.distplot(y, kde=True);
plt.show()
```

As I mentioned, ==Seaborn is really good at visualizing relationships and helping us draw insights from our data. What we will do now is demonstrate Seaborn's capacities using a very simple dataset called "Iris". This dataset is popular in introductory stats classes.==

It contains 150 rows done on 3 different plant species. Each row is an observation of a certain species of plant. The observation contains quantitive columns including length and width of its sepals and petals.

```python
iris = sns.load_dataset('iris')
iris.head()
```
We can actually visualize the _relationship_ between all these variables using a powerful function in Seaborn called .pairplot.
Conveniently, you only need one line of code to do this with Seaborn! We simply need to pass "Iris" as the data parameter, set the hue to _species_, and the size to _2.5_.

```python
sns.pairplot(iris, hue='species', height=2.5);
plt.show()
```

